{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2fb711",
   "metadata": {
    "papermill": {
     "duration": 0.007943,
     "end_time": "2024-12-24T06:05:05.405115",
     "exception": false,
     "start_time": "2024-12-24T06:05:05.397172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Necessary Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4231629d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:05.421374Z",
     "iopub.status.busy": "2024-12-24T06:05:05.421103Z",
     "iopub.status.idle": "2024-12-24T06:05:22.820353Z",
     "shell.execute_reply": "2024-12-24T06:05:22.819400Z"
    },
    "papermill": {
     "duration": 17.409514,
     "end_time": "2024-12-24T06:05:22.822975",
     "exception": false,
     "start_time": "2024-12-24T06:05:05.413461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.7)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.19.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.10/site-packages (from wandb) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.14.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (3.3)\r\n",
      "Requirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (10.3.0)\r\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2.34.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2024.5.22)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (21.3)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (0.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image) (3.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb\n",
    "! pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44970dcc",
   "metadata": {
    "papermill": {
     "duration": 0.007139,
     "end_time": "2024-12-24T06:05:22.837841",
     "exception": false,
     "start_time": "2024-12-24T06:05:22.830702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78683fe",
   "metadata": {
    "papermill": {
     "duration": 0.00708,
     "end_time": "2024-12-24T06:05:22.852138",
     "exception": false,
     "start_time": "2024-12-24T06:05:22.845058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc775a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:22.867881Z",
     "iopub.status.busy": "2024-12-24T06:05:22.867602Z",
     "iopub.status.idle": "2024-12-24T06:05:31.372700Z",
     "shell.execute_reply": "2024-12-24T06:05:31.371713Z"
    },
    "papermill": {
     "duration": 8.515289,
     "end_time": "2024-12-24T06:05:31.374552",
     "exception": false,
     "start_time": "2024-12-24T06:05:22.859263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import HfApi, HfFolder, Repository, create_repo, upload_file\n",
    "from huggingface_hub import login\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from timm.models.registry import register_model\n",
    "from huggingface_hub import hf_hub_download\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f08d4f",
   "metadata": {
    "papermill": {
     "duration": 0.007327,
     "end_time": "2024-12-24T06:05:31.389627",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.382300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07052c82",
   "metadata": {
    "papermill": {
     "duration": 0.006991,
     "end_time": "2024-12-24T06:05:31.403920",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.396929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Setup and Loading Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c568d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.420191Z",
     "iopub.status.busy": "2024-12-24T06:05:31.419315Z",
     "iopub.status.idle": "2024-12-24T06:05:31.427278Z",
     "shell.execute_reply": "2024-12-24T06:05:31.426469Z"
    },
    "papermill": {
     "duration": 0.017758,
     "end_time": "2024-12-24T06:05:31.428876",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.411118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AOHead(nn.Module):\n",
    "    def __init__(self, in_channels=768, out_channels=1):\n",
    "        super(AOHead, self).__init__()\n",
    "        \n",
    "        # Convolutional layers for further refinement of features\n",
    "        self.conv1 = nn.Conv2d(in_channels, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Output layer: Single channel for the AO map\n",
    "        self.conv_out = nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  # For output normalization to range [0, 1]\n",
    "        \n",
    "        # Upsample to 600x600\n",
    "        self.upsample = nn.Upsample(size=(600, 600), mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the AO head.\n",
    "        \n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input feature map from the ConvNeXt backbone.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: The predicted Ambient Occlusion map.\n",
    "        \"\"\"\n",
    "        # Pass through the convolutional layers with ReLU activations\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        \n",
    "        # Final output (predicting AO map)\n",
    "        x = self.conv_out(x)\n",
    "        \n",
    "        # Apply sigmoid to get values in the range [0, 1] (for visualizing AO)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        # Upsample to (600, 600)\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38411521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.444593Z",
     "iopub.status.busy": "2024-12-24T06:05:31.444317Z",
     "iopub.status.idle": "2024-12-24T06:05:31.451023Z",
     "shell.execute_reply": "2024-12-24T06:05:31.450287Z"
    },
    "papermill": {
     "duration": 0.016359,
     "end_time": "2024-12-24T06:05:31.452611",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.436252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)),\n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d02e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.468218Z",
     "iopub.status.busy": "2024-12-24T06:05:31.467977Z",
     "iopub.status.idle": "2024-12-24T06:05:31.477579Z",
     "shell.execute_reply": "2024-12-24T06:05:31.476923Z"
    },
    "papermill": {
     "duration": 0.019145,
     "end_time": "2024-12-24T06:05:31.479111",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.459966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    r\"\"\" ConvNeXt\n",
    "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, out_chans=1,\n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0.,\n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 **kwargs,):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j],\n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Output head for ambient map prediction\n",
    "        self.ao_head = AOHead(in_channels= dims[-1], out_channels=1)\n",
    "\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        features = []\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "            features.append(x)\n",
    "\n",
    "        x = self.ao_head(x)\n",
    "        features.append(x)\n",
    "\n",
    "        return features\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.forward_features(x)\n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aea0b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.494568Z",
     "iopub.status.busy": "2024-12-24T06:05:31.494300Z",
     "iopub.status.idle": "2024-12-24T06:05:31.500586Z",
     "shell.execute_reply": "2024-12-24T06:05:31.499783Z"
    },
    "papermill": {
     "duration": 0.015883,
     "end_time": "2024-12-24T06:05:31.502293",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.486410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5105f554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.517753Z",
     "iopub.status.busy": "2024-12-24T06:05:31.517507Z",
     "iopub.status.idle": "2024-12-24T06:05:31.520963Z",
     "shell.execute_reply": "2024-12-24T06:05:31.520257Z"
    },
    "papermill": {
     "duration": 0.012951,
     "end_time": "2024-12-24T06:05:31.522585",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.509634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    \"convnext_tiny_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\",\n",
    "    \"convnext_tiny_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\",\n",
    "    \"ConvNeXt_ambient_occlusion_model_1\": \"https://huggingface.co/prakanda/ConvNeXt_ambient_occlusion_model_1/resolve/main/ConvNeXt_ambient_occlusion_model_1.pth\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f5dde8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.537996Z",
     "iopub.status.busy": "2024-12-24T06:05:31.537740Z",
     "iopub.status.idle": "2024-12-24T06:05:31.545063Z",
     "shell.execute_reply": "2024-12-24T06:05:31.544412Z"
    },
    "papermill": {
     "duration": 0.016742,
     "end_time": "2024-12-24T06:05:31.546527",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.529785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convnext_tiny(pretrained=True,load_ao=True,**kwargs):\n",
    "    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    if pretrained:\n",
    "        #checkpoint = torch.load(kwargs['checkpoint'], map_location=\"cpu\")\n",
    "\n",
    "        if load_ao:\n",
    "            url = model_urls['ConvNeXt_ambient_occlusion_model_1']\n",
    "            print(\"ConvNeXt_ambient_occlusion_model_1 has been loaded.\" )\n",
    "        else:\n",
    "            url = model_urls['convnext_tiny_1k']\n",
    "            print(\"convnext_tiny_1k has been loaded\")\n",
    "\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)\n",
    "\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {}\n",
    "        unmatched_pretrained_dict = {}\n",
    "\n",
    "        for k, v in checkpoint.items():\n",
    "            if k in model_dict:\n",
    "                pretrained_dict[k] = v\n",
    "            else:\n",
    "                unmatched_pretrained_dict[k] = v\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        \n",
    "\n",
    "        print(f'The type of checkpoint is {type(checkpoint)}.')\n",
    "        print(f'The type of model.state_dict is {type(model.state_dict)}.')\n",
    "        print(f'The type of model.state_dict() is {type(model.state_dict())}.')\n",
    "\n",
    "\n",
    "        \n",
    "        for name,param in model.named_parameters():\n",
    "          if name in pretrained_dict.keys():\n",
    "              param.requires_grad = True\n",
    "          else :\n",
    "              param.requires_grad = True\n",
    "\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        print(f'The keys in pretrained_dict are : \\n {pretrained_dict.keys()}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        print(f'The keys in unmatched_pretrained_dict are : \\n {unmatched_pretrained_dict.keys()}')\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        print(\n",
    "            'Successfully loaded pretrained %d paras, and %d paras are unmatched.'\n",
    "            %(len(pretrained_dict.keys()), len(unmatched_pretrained_dict.keys())))\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        print('Unmatched pretrained paras are:', unmatched_pretrained_dict.keys())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fec272",
   "metadata": {
    "papermill": {
     "duration": 0.006932,
     "end_time": "2024-12-24T06:05:31.560584",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.553652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2a790",
   "metadata": {
    "papermill": {
     "duration": 0.006926,
     "end_time": "2024-12-24T06:05:31.574637",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.567711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract Texture and Ambient Paths from **aopatchesds** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a057d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:31.589806Z",
     "iopub.status.busy": "2024-12-24T06:05:31.589556Z",
     "iopub.status.idle": "2024-12-24T06:05:41.186800Z",
     "shell.execute_reply": "2024-12-24T06:05:41.186028Z"
    },
    "papermill": {
     "duration": 9.607001,
     "end_time": "2024-12-24T06:05:41.188745",
     "exception": false,
     "start_time": "2024-12-24T06:05:31.581744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "\n",
    "# Fetch the paths\n",
    "texture_paths = glob(\"/kaggle/input/aopatchesds/base/*.png\")\n",
    "ambient_paths = glob(\"/kaggle/input/aopatchesds/ambient/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537128e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:41.205828Z",
     "iopub.status.busy": "2024-12-24T06:05:41.205532Z",
     "iopub.status.idle": "2024-12-24T06:05:41.210773Z",
     "shell.execute_reply": "2024-12-24T06:05:41.210067Z"
    },
    "papermill": {
     "duration": 0.015567,
     "end_time": "2024-12-24T06:05:41.212402",
     "exception": false,
     "start_time": "2024-12-24T06:05:41.196835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_images_by_size(image_paths, required_size=(600, 600)):\n",
    "    \"\"\"\n",
    "    Filters a list of image paths, retaining only those with the specified size.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of image file paths to filter.\n",
    "        required_size (tuple): Desired image size (width, height) in pixels.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of image paths matching the required size.\n",
    "    \"\"\"\n",
    "    filtered_images = []\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            # Open the image to check its dimensions\n",
    "            with Image.open(image_path) as img:\n",
    "                if img.size == required_size:\n",
    "                    filtered_images.append(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbd2c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:05:41.229402Z",
     "iopub.status.busy": "2024-12-24T06:05:41.229163Z",
     "iopub.status.idle": "2024-12-24T06:24:42.391333Z",
     "shell.execute_reply": "2024-12-24T06:24:42.390320Z"
    },
    "papermill": {
     "duration": 1141.172945,
     "end_time": "2024-12-24T06:24:42.393560",
     "exception": false,
     "start_time": "2024-12-24T06:05:41.220615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "texture_paths = filter_images_by_size(texture_paths)\n",
    "ambient_paths = filter_images_by_size(ambient_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23f204b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:24:42.410741Z",
     "iopub.status.busy": "2024-12-24T06:24:42.410422Z",
     "iopub.status.idle": "2024-12-24T06:24:42.426253Z",
     "shell.execute_reply": "2024-12-24T06:24:42.425450Z"
    },
    "papermill": {
     "duration": 0.026001,
     "end_time": "2024-12-24T06:24:42.427865",
     "exception": false,
     "start_time": "2024-12-24T06:24:42.401864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the paths to ensure they align correctly\n",
    "texture_paths = texture_paths.sort()\n",
    "ambient_paths = ambient_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ae822d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:24:42.443650Z",
     "iopub.status.busy": "2024-12-24T06:24:42.443364Z",
     "iopub.status.idle": "2024-12-24T06:25:41.120747Z",
     "shell.execute_reply": "2024-12-24T06:25:41.119902Z"
    },
    "papermill": {
     "duration": 58.694948,
     "end_time": "2024-12-24T06:25:41.130251",
     "exception": false,
     "start_time": "2024-12-24T06:24:42.435303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique image sizes: {(600, 212), (212, 600), (600, 600), (212, 212)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Specify the folder containing images\n",
    "folder_path = \"/kaggle/input/aopatchesds/ambient\"\n",
    "\n",
    "# Initialize a set to store unique image sizes\n",
    "unique_sizes = set()\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    try:\n",
    "        # Open the image and get its size\n",
    "        with Image.open(file_path) as img:\n",
    "            unique_sizes.add(img.size)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with file {file_name}: {e}\")\n",
    "\n",
    "# Print the unique sizes\n",
    "print(\"Unique image sizes:\", unique_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bf974",
   "metadata": {
    "papermill": {
     "duration": 0.007055,
     "end_time": "2024-12-24T06:25:41.144704",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.137649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e088fb9",
   "metadata": {
    "papermill": {
     "duration": 0.007019,
     "end_time": "2024-12-24T06:25:41.158900",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.151881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59caad99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:25:41.174643Z",
     "iopub.status.busy": "2024-12-24T06:25:41.174313Z",
     "iopub.status.idle": "2024-12-24T06:25:41.178862Z",
     "shell.execute_reply": "2024-12-24T06:25:41.178103Z"
    },
    "papermill": {
     "duration": 0.01443,
     "end_time": "2024-12-24T06:25:41.180460",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.166030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomNormalize:\n",
    "    def __call__(self, image_tensor):\n",
    "        # Apply the given normalization directly to the tensor\n",
    "        normalized_image = torch.where(\n",
    "            image_tensor < 1,  # Condition to normalize only values less than 1.0 condition\n",
    "            torch.clamp((image_tensor - 0.7) / (1.0 - 0.68) * 0.99, min=0),  # Normalize to [0, 0.99] and clip at 0 input \n",
    "            torch.tensor(1.0)  # Keep values of 1.0 intact others\n",
    "        )\n",
    "        \n",
    "        return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2778506e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:25:41.196006Z",
     "iopub.status.busy": "2024-12-24T06:25:41.195785Z",
     "iopub.status.idle": "2024-12-24T06:25:41.202129Z",
     "shell.execute_reply": "2024-12-24T06:25:41.201398Z"
    },
    "papermill": {
     "duration": 0.015926,
     "end_time": "2024-12-24T06:25:41.203627",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.187701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextureDataset(Dataset):\n",
    "    def __init__(self, texture_paths, ambient_paths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texture_paths (list): List of paths to texture images.\n",
    "            ambient_paths (list): List of paths to ambient images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on both input and target images.\n",
    "        \"\"\"\n",
    "        self.texture_paths = texture_paths\n",
    "        self.ambient_paths = ambient_paths\n",
    "\n",
    "        \n",
    "        self.transform_rgb = transforms.Compose([\n",
    "                #transforms.Resize((600, 600)),  # Resize images\n",
    "                transforms.ToTensor(),          # Convert images to tensors\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize images (standard values for RGB)\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                transforms.ColorJitter(brightness=0.2),  # Random brightness change\n",
    "            ])\n",
    "            \n",
    "        self.transform_ao = transforms.Compose([\n",
    "                   # transforms.Resize((600, 600)), # Resize images\n",
    "                    transforms.ToTensor(), \n",
    "                    CustomNormalize(),  # Apply custom normalization\n",
    "                    transforms.Normalize(mean=[0.5], std=[0.5])  # Standard normalization\n",
    "                ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texture_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images\n",
    "        texture = Image.open(self.texture_paths[idx]).convert(\"RGB\")\n",
    "        ambient = Image.open(self.ambient_paths[idx]).convert(\"L\")\n",
    "\n",
    "        # Apply transformation to texture image (RGB)\n",
    "        if self.transform_rgb:\n",
    "            texture = self.transform_rgb(texture)\n",
    "        # Apply transformation to ambient occlusion image (AO map)\n",
    "        if self.transform_ao:\n",
    "            ambient = self.transform_ao(ambient)\n",
    "\n",
    "        return {\"input\": texture, \"target\": ambient}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde816d2",
   "metadata": {
    "papermill": {
     "duration": 0.007006,
     "end_time": "2024-12-24T06:25:41.217830",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.210824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e53b0",
   "metadata": {
    "papermill": {
     "duration": 0.007003,
     "end_time": "2024-12-24T06:25:41.232020",
     "exception": false,
     "start_time": "2024-12-24T06:25:41.225017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d05f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T06:25:41.248082Z",
     "iopub.status.busy": "2024-12-24T06:25:41.247348Z",
     "iopub.status.idle": "2024-12-24T06:25:41.827710Z",
     "shell.execute_reply": "2024-12-24T06:25:41.826511Z"
    },
    "papermill": {
     "duration": 0.589914,
     "end_time": "2024-12-24T06:25:41.829171",
     "exception": true,
     "start_time": "2024-12-24T06:25:41.239257",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_textures, test_textures, train_ambient, test_ambient \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexture_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambient_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create training and testing datasets\u001b[39;00m\n\u001b[1;32m      8\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TextureDataset(train_textures, train_ambient)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2561\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m-> 2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:331\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    329\u001b[0m         x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "train_textures, test_textures, train_ambient, test_ambient = train_test_split(\n",
    "    texture_paths, ambient_paths, test_size=0.03, random_state=20\n",
    ")\n",
    "\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = TextureDataset(train_textures, train_ambient)\n",
    "test_dataset = TextureDataset(test_textures, test_ambient)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33498728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:06:39.990012Z",
     "iopub.status.busy": "2024-12-23T09:06:39.989248Z",
     "iopub.status.idle": "2024-12-23T09:06:39.994668Z",
     "shell.execute_reply": "2024-12-23T09:06:39.993743Z",
     "shell.execute_reply.started": "2024-12-23T09:06:39.989970Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "print(f\"Number of testing batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420c809",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66164c27",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133f493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:06:41.888412Z",
     "iopub.status.busy": "2024-12-23T09:06:41.888077Z",
     "iopub.status.idle": "2024-12-23T09:06:42.831408Z",
     "shell.execute_reply": "2024-12-23T09:06:42.830457Z",
     "shell.execute_reply.started": "2024-12-23T09:06:41.888383Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = convnext_tiny(True, load_ao=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903bd9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2cca6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422237e3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.834670Z",
     "iopub.status.idle": "2024-12-22T19:23:29.835093Z",
     "shell.execute_reply": "2024-12-22T19:23:29.834896Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.834873Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set optimizer\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41ac5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdec186",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Combined Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8c042",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.836405Z",
     "iopub.status.idle": "2024-12-22T19:23:29.836836Z",
     "shell.execute_reply": "2024-12-22T19:23:29.836625Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.836603Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, ssim_weight=0, l1_weight=0.5, grad_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.ssim_weight = ssim_weight\n",
    "        self.l1_weight = l1_weight\n",
    "        self.grad_weight = grad_weight\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        # Ensure shapes match\n",
    "        if predicted.shape != target.shape:\n",
    "            raise ValueError(f\"Shape mismatch: predicted {predicted.shape}, target {target.shape}\")\n",
    "        \n",
    "        # Calculate individual losses\n",
    "        ssim_loss = self.ssim(predicted, target)\n",
    "        l1_loss = self.l1(predicted, target)\n",
    "        grad_loss = self.gradient_loss(predicted, target)\n",
    "        \n",
    "        # Combine the losses with the specified weights\n",
    "        total_loss = self.ssim_weight * ssim_loss + self.l1_weight * l1_loss + self.grad_weight * grad_loss\n",
    "        return total_loss\n",
    "\n",
    "    def ssim(self, predicted, target):\n",
    "        \"\"\"\n",
    "        Calculate the Structural Similarity Index (SSIM) between predicted and target for the whole batch.\n",
    "        \"\"\"\n",
    "        predicted_np = predicted.cpu().detach().numpy()\n",
    "        target_np = target.cpu().detach().numpy()\n",
    "\n",
    "        batch_size = predicted.shape[0]\n",
    "        ssim_loss = 0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            predicted_image = np.clip(predicted_np[i, 0, :, :], 0, 1)\n",
    "            target_image = np.clip(target_np[i, 0, :, :], 0, 1)\n",
    "            try:\n",
    "                ssim_value = ssim(predicted_image, target_image, data_range=1.0, win_size=7)\n",
    "                ssim_loss += (1 - ssim_value)\n",
    "            except ValueError:\n",
    "                ssim_loss += 1\n",
    "        \n",
    "        ssim_loss /= batch_size\n",
    "        return ssim_loss\n",
    "\n",
    "    def l1(self, predicted, target):\n",
    "        \"\"\"Calculate the L1 Loss between predicted and target.\"\"\"\n",
    "        return F.l1_loss(predicted, target)\n",
    "        \n",
    "    def gradient_loss(self, predicted, target):\n",
    "        \"\"\"Calculate the gradient loss.\"\"\"\n",
    "        grad_pred_x = predicted[:, :, 1:, :] - predicted[:, :, :-1, :]\n",
    "        grad_pred_y = predicted[:, :, :, 1:] - predicted[:, :, :, :-1]\n",
    "\n",
    "        grad_target_x = target[:, :, 1:, :] - target[:, :, :-1, :]\n",
    "        grad_target_y = target[:, :, :, 1:] - target[:, :, :, :-1]\n",
    "\n",
    "        grad_loss_x = F.l1_loss(grad_pred_x, grad_target_x)\n",
    "        grad_loss_y = F.l1_loss(grad_pred_y, grad_target_y)\n",
    "\n",
    "        return grad_loss_x + grad_loss_y\n",
    "\n",
    "\n",
    "# Initialize Model with Proper Weight Initialization\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Applies Xavier initialization for weights and zeroes for biases to ensure \n",
    "    proper gradient flow in the network.\n",
    "    \"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93feef50",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.838013Z",
     "iopub.status.idle": "2024-12-22T19:23:29.838464Z",
     "shell.execute_reply": "2024-12-22T19:23:29.838246Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.838223Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the CombinedLoss\n",
    "criterion = CombinedLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81703b69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e023f57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Logging into Weights & Biases (W&B) Using a User Secret API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1322c0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.839683Z",
     "iopub.status.idle": "2024-12-22T19:23:29.840132Z",
     "shell.execute_reply": "2024-12-22T19:23:29.839908Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.839887Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a generic user secret\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    " \n",
    "#Login to W&B using the retrieved API key\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0098a3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6a381",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Saving and Uploading a PyTorch Model to the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72284d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.841819Z",
     "iopub.status.idle": "2024-12-22T19:23:29.842249Z",
     "shell.execute_reply": "2024-12-22T19:23:29.842043Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.842022Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the Hugging Face token from environment variables (ensure it's set in your Kaggle environment)\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "# Log in using the token\n",
    "login(token=hf_token)\n",
    "\n",
    "repo_name = \"AO_Model\"\n",
    "create_repo(repo_name, exist_ok=True)\n",
    "\n",
    "def save_to_huggingface(model):\n",
    "    # Save the model to a .pth file\n",
    "    save_path = \"AO_Model.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved locally to {save_path}\")\n",
    "\n",
    "    upload_file(\n",
    "        path_or_fileobj=save_path,\n",
    "        path_in_repo=save_path,\n",
    "        repo_id=f\"prakanda/{repo_name}\",  # Replace with your Hugging Face username\n",
    "        token=hf_token  # Using the token from environment variable\n",
    "    )\n",
    "    print(f\"Model uploaded to ambient Hub: https://huggingface.co/prakanda/{repo_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5daeb5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40062d63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f983b68",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.843794Z",
     "iopub.status.idle": "2024-12-22T19:23:29.844217Z",
     "shell.execute_reply": "2024-12-22T19:23:29.844016Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.843994Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device0=\"cuda:0\"\n",
    "num_epochs = 10\n",
    "wandb.init(project=\"AO-Model-Evaluation\", config={\"epochs\": 10, \"batch_size\": 2, \"learning_rate\": 1e-4})\n",
    "\n",
    "\n",
    "# Move the model to the GPU before the training loop\n",
    "model.to(device0) \n",
    "\n",
    "max_grad_norm = 1.0  # Set the gradient clipping norm\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # Move inputs, targets, and camera_intrinsic to the device\n",
    "        inputs = batch[\"input\"].to(device0, non_blocking=True)\n",
    "        targets = batch[\"target\"].to(device0, non_blocking=True)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted_ambient = outputs[-1]\n",
    "\n",
    "        # Use the criterion for ambient loss calculation\n",
    "        loss = criterion(predicted_ambient, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Log progress every 10 batches\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "            wandb.log({\"epoch\": epoch + 1, \"batch_loss\": loss.item()})\n",
    "\n",
    "        # Save the model every 1000 batches\n",
    "        if batch_idx != 0 and batch_idx % 1000 == 0:\n",
    "            print(\"Saving model\")\n",
    "            save_to_huggingface(model)\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    average_loss_per_epoch = running_loss / len(train_dataloader)\n",
    "    wandb.log({\"epoch\": epoch + 1, \"average_loss_per_epoch\": average_loss_per_epoch})\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss_per_epoch:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffa7e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516129ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Loading Model from ambient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc99426",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.845761Z",
     "iopub.status.idle": "2024-12-22T19:23:29.846188Z",
     "shell.execute_reply": "2024-12-22T19:23:29.845983Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.845960Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the Hugging Face token from environment variables (ensure it's set in your Kaggle environment)\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "# Log in using the token\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b175555",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.848042Z",
     "iopub.status.idle": "2024-12-22T19:23:29.848489Z",
     "shell.execute_reply": "2024-12-22T19:23:29.848272Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.848250Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the model file from Hugging Face Hub\n",
    "repo_name = \"AO_Model\"\n",
    "downloaded_file = hf_hub_download(\n",
    "    repo_id=f\"prakanda/{repo_name}\",  # Replace with your Hugging Face username\n",
    "    filename=\"AO_Model.pth\"\n",
    ")\n",
    "print(f\"Model downloaded from Hugging Face Hub: {downloaded_file}\")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model and load the state_dict\n",
    "\n",
    "model.load_state_dict(torch.load(downloaded_file),strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e85ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0d9f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec68725",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-22T19:23:29.851794Z",
     "iopub.status.idle": "2024-12-22T19:23:29.852223Z",
     "shell.execute_reply": "2024-12-22T19:23:29.852015Z",
     "shell.execute_reply.started": "2024-12-22T19:23:29.851994Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device0=\"cuda:0\"\n",
    "wandb.init(project=\"AO-Model-Evaluation\", config={\"batch_size\": 2, \"learning_rate\": 1e-4})\n",
    "\n",
    "def evaluate(model, test_dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0  # Accumulate loss over all batches\n",
    "    total_samples = 0   # Track the number of processed samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader):\n",
    "            # Move inputs and targets to the device\n",
    "            inputs = batch[\"input\"].to(device0, non_blocking=True)\n",
    "            targets = batch[\"target\"].to(device0, non_blocking=True)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            predicted_ambient= outputs[-1]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(predicted_ambient, targets)\n",
    "\n",
    "            # Accumulate running loss and sample count\n",
    "            running_loss += loss.item() * inputs.size(0)  # Weighted by batch size\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            # Log progress every 10 batches\n",
    "            if batch_idx % 40 == 0:\n",
    "                print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                wandb.log({\"batch_number\": batch_idx,\"batch_loss\": loss.item()})\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate average loss over the dataset\n",
    "        avg_loss = running_loss / total_samples\n",
    "        return avg_loss\n",
    "\n",
    "# Perform evaluation on the test set\n",
    "test_loss = evaluate(model, test_dataloader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Log the average test loss to W&B\n",
    "wandb.log({\"average_test_loss\": test_loss})\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6211511,
     "sourceId": 10076639,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6220263,
     "sourceId": 10088214,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6220624,
     "sourceId": 10088660,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6222017,
     "sourceId": 10090456,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6256336,
     "sourceId": 10137083,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6279702,
     "sourceId": 10186733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6321457,
     "sourceId": 10225130,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6356189,
     "sourceId": 10272771,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1240.496435,
   "end_time": "2024-12-24T06:25:43.459606",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-24T06:05:02.963171",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
